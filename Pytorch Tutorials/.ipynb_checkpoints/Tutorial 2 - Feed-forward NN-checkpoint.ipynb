{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feed-Forward Neural Network on CIFAR Data\n",
    "\n",
    "First, import some libraries and some functions to get pretty looking plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.autograd import Variable\n",
    "\n",
    "# Make matplotlib plot pretty pictures\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (16.0, 14.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "# Reload external modules\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network Definition\n",
    "\n",
    "A neural network class needs to have two functions - \n",
    "\n",
    "1. `__init__` : Here, you specify the size of the net, and the number and type of layers it has.\n",
    "    * We have one hidden layer of size `hidden_size`, the `input_size` and the output size is `num_classes`.\n",
    "    \n",
    "2. `forward` : Define the forward propagation through your layers.\n",
    "    \n",
    "    * In the example below, there's a fully-connected layer -> RELU -> fully-connected layer -> output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural Network Model (1 hidden layer)\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size) \n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size, num_classes)  \n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperparameters\n",
    "\n",
    "* `num_epochs` : The number of sweeps of your entire training data you wish to do.\n",
    "* `batch_size` : The number of datapoints you take for each SGD step\n",
    "* There could be other hyperparameters as well, such as learning rate decay."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper Parameters \n",
    "input_size = 32*32*3\n",
    "hidden_size = 500\n",
    "num_classes = 10\n",
    "num_epochs = 5\n",
    "batch_size = 100\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Working with the CIFAR10 Dataset\n",
    "\n",
    "1. Download the data, and split it into training and test sets\n",
    "2. Plot some images in the CIFAR10 set, to understand what we're dealing with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CIFAR10 Dataset \n",
    "train_dataset = dsets.CIFAR10(root='./data', \n",
    "                            train=True, \n",
    "                            transform=transforms.ToTensor(),  \n",
    "                            download=False)\n",
    "\n",
    "test_dataset = dsets.CIFAR10(root='./data', \n",
    "                           train=False, \n",
    "                           transform=transforms.ToTensor())\n",
    "\n",
    "# Data Loader (Input Pipeline)\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n",
    "                                           batch_size=batch_size, \n",
    "                                           shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, \n",
    "                                          batch_size=batch_size, \n",
    "                                          shuffle=False)\n",
    "\n",
    "# Explore the data\n",
    "data_iter = iter(train_loader)\n",
    "\n",
    "# Mini-batch images and labels.\n",
    "images, labels = data_iter.next()\n",
    "\n",
    "# Explore the CIFAR Data\n",
    "X_train = 255*np.moveaxis(images.numpy(), 1, -1)\n",
    "y_train = labels.numpy()\n",
    "\n",
    "classes = ['plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "num_classes = len(classes)\n",
    "samples_per_class = 5\n",
    "for y, cls in enumerate(classes):\n",
    "\tids = np.flatnonzero(y_train == y)\n",
    "\tids = np.random.choice(ids, samples_per_class, replace=False)\n",
    "\n",
    "\tfor i, idxs in enumerate(ids):\n",
    "\t\tplt_idx = i*num_classes+y+1\n",
    "\t\tplt.subplot(samples_per_class, num_classes, plt_idx)\n",
    "\t\tplt.imshow(X_train[idxs].astype('uint8'))\n",
    "\t\tplt.axis('off')\n",
    "\t\tif i == 0:\n",
    "\t\t\tplt.title(cls)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize and train the neural network\n",
    "\n",
    "net = Net(input_size, hidden_size, num_classes)\n",
    "net.cuda()   # Tells PyTorch to use the GPU instead of the CPU \n",
    "    \n",
    "# Loss and Optimizer\n",
    "criterion = nn.CrossEntropyLoss()   # This is softmax loss\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=learning_rate)  \n",
    "\n",
    "# Train the Model\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):  \n",
    "        # Convert torch tensor to Variable\n",
    "        images = Variable(images.view(-1, 32*32*3).cuda()) #.cuda() just tells Pytorch to shift everything to the GPU\n",
    "        labels = Variable(labels.cuda())\n",
    "        \n",
    "        # Forward + Backward + Optimize\n",
    "        optimizer.zero_grad()  # zero the gradient buffer\n",
    "        outputs = net(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (i+1) % 100 == 0:\n",
    "            print ('Epoch [%d/%d], Step [%d/%d], Loss: %.4f' \n",
    "                   %(epoch+1, num_epochs, i+1, len(train_dataset)//batch_size, loss.data[0]))\n",
    "\n",
    "# Test the Model\n",
    "correct = 0\n",
    "total = 0\n",
    "for images, labels in test_loader:\n",
    "    images = Variable(images.view(-1, 32*32*3)).cuda()\n",
    "    outputs = net(images)\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    total += labels.size(0)\n",
    "    correct += (predicted.cpu() == labels).sum()\n",
    "\n",
    "print('Accuracy of the network on the 10000 test images: %d %%' % (100 * correct / total))\n",
    "\n",
    "# Save the Model\n",
    "torch.save(net.state_dict(), 'model.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
